
@book{russell_artificial_2021,
	edition = {4th Edition},
	title = {Artificial Intelligence: A Modern Approach},
	pagetotal = {1115},
	publisher = {Pearson},
	author = {Russell, Stuart and Norvig, Peter},
	date = {2021-04-15},
	langid = {english},
	file = {Artificial Intelligence\: A Modern Approach:C\:\\Users\\micha\\Zotero\\storage\\Q94WTGU2\\Artificial Intelligence A Modern Approach.pdf:application/pdf},
}

@book{burkov_hundred_2019,
	title = {The Hundred Page Machine Learning Book},
	pagetotal = {160},
	author = {Burkov, Andriy},
	date = {2019-01-13},
	langid = {english},
	file = {The Hundred Page Machine Learning:C\:\\Users\\micha\\Zotero\\storage\\WNJCUQIZ\\The Hundred Page Machine Learning.pdf:application/pdf},
}

@book{muller_introduction_2016,
	title = {Introduction to Machine Learning with Python: A Guide for Data Scientists},
	isbn = {978-1-4493-6990-3},
	shorttitle = {Introduction to Machine Learning with Python},
	abstract = {Machine learning has become an integral part of many commercial applications and research projects, but this field is not exclusive to large companies with extensive research teams. If you use Python, even as a beginner, this book will teach you practical ways to build your own machine learning solutions. With all the data available today, machine learning applications are limited only by your imagination.You’ll learn the steps necessary to create a successful machine-learning application with Python and the scikit-learn library. Authors Andreas Müller and Sarah Guido focus on the practical aspects of using machine learning algorithms, rather than the math behind them. Familiarity with the {NumPy} and matplotlib libraries will help you get even more from this book.With this book, you’ll learn:Fundamental concepts and applications of machine {learningAdvantages} and shortcomings of widely used machine learning {algorithmsHow} to represent data processed by machine learning, including which data aspects to focus {onAdvanced} methods for model evaluation and parameter {tuningThe} concept of pipelines for chaining models and encapsulating your {workflowMethods} for working with text data, including text-specific processing {techniquesSuggestions} for improving your machine learning and data science skills},
	pagetotal = {400},
	publisher = {"O'Reilly Media, Inc."},
	author = {Müller, Andreas C. and Guido, Sarah},
	date = {2016-09-26},
	langid = {english},
	keywords = {Computers / Artificial Intelligence / Natural Language Processing, Computers / General, Computers / Languages / General, Computers / Languages / Python, Computers / Programming / Algorithms, Computers / Programming / General, Computers / Programming / Open Source},
}

@book{theobald_machine_2017,
	title = {Machine Learning For Absolute Beginners},
	pagetotal = {164},
	author = {Theobald, Oliver},
	date = {2017-06-21},
	langid = {english},
	file = {Theobald - Machine Learning For Absolute Beginners.pdf:C\:\\Users\\micha\\Zotero\\storage\\K7E2EIJX\\Theobald - Machine Learning For Absolute Beginners.pdf:application/pdf},
}

@book{mettrie_mensch_2014,
	title = {Der Mensch eine Maschine},
	pagetotal = {76},
	author = {Mettrie, Julien Offray de La},
	date = {2014-12-19},
}

@article{scherk_kunstliche_2017,
	title = {Künstliche Intelligenz-Artificial Intelligence},
	journaltitle = {A Report commissioned by the German Federal Ministry of Transport and Infrastructure},
	author = {Scherk, Johannes and Pöchhacker-Tröscher, Gerlinde and Wagner, Karina},
	date = {2017},
	file = {Full Text:C\:\\Users\\micha\\Zotero\\storage\\GD78FI3H\\Scherk et al. - 2017 - Künstliche Intelligenz-Artificial Intelligence.pdf:application/pdf},
}

@misc{scherk_johannes_bsc_kunstliche_2017,
	title = {Künstliche Intelligenz - Artificial Intelligence},
	author = {{Scherk Johannes B.Sc.} and {Mag. Gerlinde Pöchhacker-Tröscher} and {Karina Wagner B.Sc.}},
	date = {2017-05},
	file = {BVMIT Dossier Artificial Intelligence 2017 FINAL.pdf:C\:\\Users\\micha\\Zotero\\storage\\C6E84Y3F\\BVMIT Dossier Artificial Intelligence 2017 FINAL.pdf:application/pdf},
}

@book{hobbes_leviathan_2020,
	title = {Leviathan by Thomas Hobbes},
	isbn = {9798612391401},
	pagetotal = {304},
	publisher = {Independently published},
	author = {Hobbes, Thomas},
	date = {2020-03-04},
}

@book{hobbes_leviathan_1986,
	location = {Ditzingen},
	title = {Leviathan},
	isbn = {978-3-15-008348-2},
	pagetotal = {327},
	publisher = {Reclam},
	author = {Hobbes, Thomas and Diesselhorst, Malte},
	translator = {Mayer, Jacob Peter},
	date = {1986-01-01},
}

@article{oleary_artificial_2013,
	title = {Artificial Intelligence and Big Data},
	volume = {28},
	issn = {1941-1294},
	doi = {10.1109/MIS.2013.39},
	abstract = {{AI} Innovation in Industry is a new department for {IEEE} Intelligent Systems, and this paper examines some of the basic concerns and uses of {AI} for big data ({AI} has been used in several different ways to facilitate capturing and structuring big data, and it has been used to analyze big data for key insights).},
	pages = {96--99},
	number = {2},
	journaltitle = {{IEEE} Intelligent Systems},
	author = {O'Leary, Daniel E.},
	date = {2013-03},
	note = {Conference Name: {IEEE} Intelligent Systems},
	keywords = {{AI}, artificial intelligence, Artificial intelligence, big data, Data handling, Data storage systems, Information management, intelligent systems, Internet, Machine learning algorithms, parallelization, visualization},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\micha\\Zotero\\storage\\GNSMTEAB\\O'Leary - 2013 - Artificial Intelligence and Big Data.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\micha\\Zotero\\storage\\IISD7GQJ\\6547979.html:text/html},
}

@inproceedings{le_using_2017,
	title = {Using synthetic data to train neural networks is model-based reasoning},
	doi = {10.1109/IJCNN.2017.7966298},
	abstract = {We draw a formal connection between using synthetic training data to optimize neural network parameters and approximate, Bayesian, model-based reasoning. In particular, training a neural network using synthetic data can be viewed as learning a proposal distribution generator for approximate inference in the synthetic-data generative model. We demonstrate this connection in a recognition task where we develop a novel Captcha-breaking architecture and train it using synthetic data, demonstrating both state-of-the-art performance and a way of computing task-specific posterior uncertainty. Using a neural network trained this way, we also demonstrate successful breaking of real-world Captchas currently used by Facebook and Wikipedia. Reasoning from these empirical results and drawing connections with Bayesian modeling, we discuss the robustness of synthetic data results and suggest important considerations for ensuring good neural network generalization when training with synthetic data.},
	eventtitle = {2017 International Joint Conference on Neural Networks ({IJCNN})},
	pages = {3514--3521},
	booktitle = {2017 International Joint Conference on Neural Networks ({IJCNN})},
	author = {Le, Tuan Anh and Baydin, Atilim Giineş and Zinkov, Robert and Wood, Frank},
	date = {2017-05},
	note = {{ISSN}: 2161-4407},
	keywords = {{CAPTCHAs}, Computational modeling, Data models, Generators, Neural networks, Training, Training data},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\micha\\Zotero\\storage\\7YEWUVAQ\\Le et al. - 2017 - Using synthetic data to train neural networks is m.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\micha\\Zotero\\storage\\DDIHHXPM\\7966298.html:text/html},
}

@article{nikolenko_synthetic_2019,
	title = {Synthetic Data for Deep Learning},
	url = {http://arxiv.org/abs/1909.11512},
	abstract = {Synthetic data is an increasingly popular tool for training deep learning models, especially in computer vision but also in other areas. In this work, we attempt to provide a comprehensive survey of the various directions in the development and application of synthetic data. First, we discuss synthetic datasets for basic computer vision problems, both low-level (e.g., optical flow estimation) and high-level (e.g., semantic segmentation), synthetic environments and datasets for outdoor and urban scenes (autonomous driving), indoor scenes (indoor navigation), aerial navigation, simulation environments for robotics, applications of synthetic data outside computer vision (in neural programming, bioinformatics, {NLP}, and more); we also survey the work on improving synthetic data development and alternative ways to produce it such as {GANs}. Second, we discuss in detail the synthetic-to-real domain adaptation problem that inevitably arises in applications of synthetic data, including synthetic-to-real refinement with {GAN}-based models and domain adaptation at the feature/model level without explicit data transformations. Third, we turn to privacy-related applications of synthetic data and review the work on generating synthetic datasets with differential privacy guarantees. We conclude by highlighting the most promising directions for further work in synthetic data studies.},
	journaltitle = {{arXiv}:1909.11512 [cs]},
	author = {Nikolenko, Sergey I.},
	urldate = {2021-12-11},
	date = {2019-09-25},
	eprinttype = {arxiv},
	eprint = {1909.11512},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Cryptography and Security, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\micha\\Zotero\\storage\\46EUNE5G\\Nikolenko - 2019 - Synthetic Data for Deep Learning.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\micha\\Zotero\\storage\\4W43385Z\\1909.html:text/html},
}

@online{wko_tax_2021,
	title = {Tax free shopping - Wichtige Hinweise für Touristen},
	url = {https://www.wko.at/service/steuern/Tax_free_shopping_-_Wichtige_Hinweise_fuer_Touristen.html},
	shorttitle = {Tax free shopping - wichtige Hinweise für Touristen},
	abstract = {Rückerstattung der Umsatzsteuer},
	titleaddon = {wko.at},
	author = {{WKO}},
	urldate = {2021-12-13},
	date = {2021-05-01},
	langid = {german},
	file = {Snapshot:C\:\\Users\\micha\\Zotero\\storage\\GDKA2JKX\\Tax_free_shopping_-_Wichtige_Hinweise_fuer_Touristen.html:text/html},
}

@collection{kao_natural_2007,
	location = {London},
	title = {Natural language processing and text mining},
	isbn = {978-1-84628-175-4},
	pagetotal = {265},
	publisher = {Springer},
	editor = {Kao, Anne and Poteet, Stephen R.},
	date = {2007},
	langid = {english},
	keywords = {Data mining, Natural language processing (Computer science)},
	file = {Kao und Poteet - 2007 - Natural language processing and text mining.pdf:C\:\\Users\\micha\\Zotero\\storage\\U4WBBSC6\\Kao und Poteet - 2007 - Natural language processing and text mining.pdf:application/pdf},
}

@book{epstein_parsing_2008,
	location = {Dordrecht, {NETHERLANDS}, {THE}},
	title = {Parsing the Turing Test: Philosophical and Methodological Issues in the Quest for the Thinking Computer},
	isbn = {978-1-4020-6710-5},
	url = {http://ebookcentral.proquest.com/lib/fhwnat/detail.action?docID=338491},
	shorttitle = {Parsing the Turing Test},
	publisher = {Springer Netherlands},
	author = {Epstein, Robert and Roberts, Gary and Beber, Grace},
	urldate = {2022-01-11},
	date = {2008},
	keywords = {Artificial intelligence -- Methodology., Artificial intelligence.},
	file = {ProQuest Ebook Snapshot:C\:\\Users\\micha\\Zotero\\storage\\5UAW5AR7\\reader.html:text/html},
}

@article{polettini_maximum_nodate,
	title = {Maximum entropy simulation for microdata protection},
	abstract = {The paper proposes a new disclosure limitation procedure based on simulation. The key feature of the proposal is to protect actual microdata by drawing artiﬁcial units from a probability model, that is estimated from the observed data. Such a model is designed to maintain selected characteristics of the empirical distribution, thus providing a partial representation of the latter. The characteristics we focus on are the expected values of a set of functions; these are constrained to be equal to their corresponding sample averages; the simulated data, then, reproduce on average the sample characteristics. If the set of constraints covers the parameters of interest of a user, information loss is controlled for, while, as the model does not preserve individual values, re-identiﬁcation attempts are impaired-synthetic individuals correspond to actual respondents with very low probability. Disclosure is mainly discussed from the viewpoint of record re-identiﬁcation. According to this deﬁnition, as the pledge for conﬁdentiality only involves the actual respondents, release of synthetic units should in principle rule out the concern for conﬁdentiality. The simulation model is built on the Italian sample from the Community Innovation Survey ({CIS}). The approach can be applied in more generality, and especially suits quantitative traits. The model has a semi-parametric component, based on the maximum entropy principle, and, here, a parametric component, based on regression. The maximum entropy principle is exploited to match data traits; moreover, entropy measures uncertainty of a distribution: its maximisation leads to a distribution which is consistent with the given information but is maximally noncommittal with regard to missing information. Application results reveal that the ﬁxed characteristics are sustained, and other features such as marginal distributions are well represented. Model speciﬁcation is clearly a major point; related issues are selection of characteristics, goodness of ﬁt and strength of dependence relations.},
	pages = {14},
	author = {Polettini, Silvia},
	langid = {english},
	file = {Polettini - Maximum entropy simulation for microdata protectio.pdf:C\:\\Users\\micha\\Zotero\\storage\\D3PWSE2J\\Polettini - Maximum entropy simulation for microdata protectio.pdf:application/pdf},
}

@article{drechsler_comparing_2008,
	title = {Comparing Fully and Partially Synthetic Datasets for Statistical Disclosure Control in the German {IAB} Establishment Panel},
	pages = {26},
	author = {Drechsler, Jörg and Bender, Stefan and Rässler, Susanne},
	date = {2008},
	langid = {english},
	file = {Drechsler et al. - 2008 - Comparing Fully and Partially Synthetic Datasets f.pdf:C\:\\Users\\micha\\Zotero\\storage\\HSCYWUCG\\Drechsler et al. - 2008 - Comparing Fully and Partially Synthetic Datasets f.pdf:application/pdf},
}

@misc{jan-philipp_kolb_methoden_nodate,
	title = {Methoden zur Erzeugung synthetischer Simulationsgesamtheiten},
	author = {{Jan-Philipp Kolb}},
	file = {Methoden zur Erzeugung synthetischer Simulationsgesamtheiten.pdf:C\:\\Users\\micha\\Zotero\\storage\\LJVCYIP4\\Methoden zur Erzeugung synthetischer Simulationsgesamtheiten.pdf:application/pdf},
}

@inproceedings{tripathi_learning_2019,
	location = {Long Beach, {CA}, {USA}},
	title = {Learning to Generate Synthetic Data via Compositing},
	isbn = {978-1-72813-293-8},
	url = {https://ieeexplore.ieee.org/document/8953554/},
	doi = {10.1109/CVPR.2019.00055},
	abstract = {We present a task-aware approach to synthetic data generation. Our framework employs a trainable synthesizer network that is optimized to produce meaningful training samples by assessing the strengths and weaknesses of a ‘target’ network. The synthesizer and target networks are trained in an adversarial manner wherein each network is updated with a goal to outdo the other. Additionally, we ensure the synthesizer generates realistic data by pairing it with a discriminator trained on real-world images. Further, to make the target classiﬁer invariant to blending artefacts, we introduce these artefacts to background regions of the training images so the target does not over-ﬁt to them.},
	eventtitle = {2019 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	pages = {461--470},
	booktitle = {2019 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	publisher = {{IEEE}},
	author = {Tripathi, Shashank and Chandra, Siddhartha and Agrawal, Amit and Tyagi, Ambrish and Rehg, James M. and Chari, Visesh},
	urldate = {2022-02-08},
	date = {2019-06},
	langid = {english},
	file = {Tripathi et al. - 2019 - Learning to Generate Synthetic Data via Compositin.pdf:C\:\\Users\\micha\\Zotero\\storage\\C4E6VI69\\Tripathi et al. - 2019 - Learning to Generate Synthetic Data via Compositin.pdf:application/pdf},
}

@inproceedings{tripathi_learning_2019-1,
	location = {Long Beach, {CA}, {USA}},
	title = {Learning to Generate Synthetic Data via Compositing},
	isbn = {978-1-72813-293-8},
	url = {https://ieeexplore.ieee.org/document/8953554/},
	doi = {10.1109/CVPR.2019.00055},
	abstract = {We present a task-aware approach to synthetic data generation. Our framework employs a trainable synthesizer network that is optimized to produce meaningful training samples by assessing the strengths and weaknesses of a ‘target’ network. The synthesizer and target networks are trained in an adversarial manner wherein each network is updated with a goal to outdo the other. Additionally, we ensure the synthesizer generates realistic data by pairing it with a discriminator trained on real-world images. Further, to make the target classiﬁer invariant to blending artefacts, we introduce these artefacts to background regions of the training images so the target does not over-ﬁt to them.},
	eventtitle = {2019 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	pages = {461--470},
	booktitle = {2019 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	publisher = {{IEEE}},
	author = {Tripathi, Shashank and Chandra, Siddhartha and Agrawal, Amit and Tyagi, Ambrish and Rehg, James M. and Chari, Visesh},
	urldate = {2022-02-08},
	date = {2019-06},
	langid = {english},
	file = {Tripathi et al. - 2019 - Learning to Generate Synthetic Data via Compositin.pdf:C\:\\Users\\micha\\Zotero\\storage\\9DHTTZPT\\Tripathi et al. - 2019 - Learning to Generate Synthetic Data via Compositin.pdf:application/pdf},
}

@inproceedings{tremblay_training_2018,
	location = {Salt Lake City, {UT}},
	title = {Training Deep Networks with Synthetic Data: Bridging the Reality Gap by Domain Randomization},
	isbn = {978-1-5386-6100-0},
	url = {https://ieeexplore.ieee.org/document/8575297/},
	doi = {10.1109/CVPRW.2018.00143},
	shorttitle = {Training Deep Networks with Synthetic Data},
	abstract = {We present a system for training deep neural networks for object detection using synthetic images. To handle the variability in real-world data, the system relies upon the technique of domain randomization, in which the parameters of the simulator—such as lighting, pose, object textures, etc.—are randomized in non-realistic ways to force the neural network to learn the essential features of the object of interest. We explore the importance of these parameters, showing that it is possible to produce a network with compelling performance using only non-artisticallygenerated synthetic data. With additional ﬁne-tuning on real data, the network yields better performance than using real data alone. This result opens up the possibility of using inexpensive synthetic data for training neural networks while avoiding the need to collect large amounts of handannotated real-world data or to generate high-ﬁdelity synthetic worlds—both of which remain bottlenecks for many applications. The approach is evaluated on bounding box detection of cars on the {KITTI} dataset.},
	eventtitle = {2018 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition Workshops ({CVPRW})},
	pages = {1082--10828},
	booktitle = {2018 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition Workshops ({CVPRW})},
	publisher = {{IEEE}},
	author = {Tremblay, Jonathan and Prakash, Aayush and Acuna, David and Brophy, Mark and Jampani, Varun and Anil, Cem and To, Thang and Cameracci, Eric and Boochoon, Shaad and Birchfield, Stan},
	urldate = {2022-02-08},
	date = {2018-06},
	langid = {english},
	file = {Tremblay et al. - 2018 - Training Deep Networks with Synthetic Data Bridgi.pdf:C\:\\Users\\micha\\Zotero\\storage\\RX3BPTUY\\Tremblay et al. - 2018 - Training Deep Networks with Synthetic Data Bridgi.pdf:application/pdf},
}

@incollection{hoag_parallel_2010,
	location = {Boston, {MA}},
	title = {A Parallel General-Purpose Synthetic Data Generator1},
	isbn = {978-1-4419-0176-7},
	url = {https://doi.org/10.1007/978-1-4419-0176-7_6},
	series = {International Series in Operations Research \& Management Science},
	abstract = {The {IT} industry needs synthetic data generation tools for a number of applications including (but not limited to): Regression testing. Repeatedly generate the same large data set for testing enterprise applications. Allow the data set to be removed between regression tests.},
	pages = {103--117},
	booktitle = {Data Engineering: Mining, Information and Intelligence},
	publisher = {Springer {US}},
	author = {Hoag, Joseph E. and Thompson, Craig W.},
	editor = {Chan, Yupo and Talburt, John and Talley, Terry M.},
	urldate = {2022-02-08},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-1-4419-0176-7_6},
	keywords = {Distribution Constraint, Field Element, Generation Process, Mailing List, Synthetic Data},
}

@incollection{varol_application_2010,
	location = {Boston, {MA}},
	title = {Application of the Near Miss Strategy and Edit Distance to Handle Dirty Data},
	isbn = {978-1-4419-0176-7},
	url = {https://doi.org/10.1007/978-1-4419-0176-7_5},
	series = {International Series in Operations Research \& Management Science},
	abstract = {In today’s information age, processing customer information in a standardized and accurate manner is known to be a difficult task. Data collection methods vary from source to source by format, volume, and media type. Therefore, it is advantageous to deploy customized data hygiene techniques to standardize the data for meaningfulness and usefulness based on the organization.},
	pages = {91--101},
	booktitle = {Data Engineering: Mining, Information and Intelligence},
	publisher = {Springer {US}},
	author = {Varol, Cihan and Bayrak, Coskun and Wagner, Rick and Goff, Dana},
	editor = {Chan, Yupo and Talburt, John and Talley, Terry M.},
	urldate = {2022-02-08},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-1-4419-0176-7_5},
	keywords = {Cognitive Error, Edit Distance, Optical Character Recognition, Spelling Correction, Spelling Error},
}

@incollection{chan_looking_2010,
	location = {Boston, {MA}},
	title = {Looking Ahead},
	isbn = {978-1-4419-0176-7},
	url = {https://doi.org/10.1007/978-1-4419-0176-7_19},
	series = {International Series in Operations Research \& Management Science},
	abstract = {The enthusiasm of our contributing authors and their convincing messages have demonstrated the great potential of advances in information quality, analytics, and visualization to improve the quality of information-based decision making. We, the editors and the contributing authors, hope that this book will have some impact on the practice of managers and technical personnel immediately upon its publication and in the years to come.},
	pages = {431--439},
	booktitle = {Data Engineering: Mining, Information and Intelligence},
	publisher = {Springer {US}},
	author = {Chan, Yupo and Talburt, John and Talley, Terry},
	editor = {Chan, Yupo and Talburt, John and Talley, Terry M.},
	urldate = {2022-02-08},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-1-4419-0176-7_19},
	keywords = {Cloud Computing, Data Integration, Information Quality, Latent Semantic Indexing, Transitive Closure},
}

@incollection{talley_introduction_2010,
	location = {Boston, {MA}},
	title = {Introduction},
	isbn = {978-1-4419-0176-7},
	url = {https://doi.org/10.1007/978-1-4419-0176-7_1},
	series = {International Series in Operations Research \& Management Science},
	abstract = {Many companies and organizations face the common problem illustrated in Figure 1.1. The challenge is to take data from the real world and convert it into a model that can be used for decision making. For example, the model can be used as a tool to drive campaigns. The purpose of these campaigns is to affect the real world in a positive way from the perspective of the organization running the campaign. The general process is to collect data from a number of sources, then integrate that data into a consistent and logically related set of data. The integrated data is stored in a repository. This repository is often called a data warehouse and is often stored in a commercial relational database. Using the data, mathematical techniques, and algorithms, a model of the real world is constructed to support the decision making process. A variety of campaign management tools then use the model to drive campaigns executed in the real world.},
	pages = {1--16},
	booktitle = {Data Engineering: Mining, Information and Intelligence},
	publisher = {Springer {US}},
	author = {Talley, Terry M. and Talburt, John R. and Chan, Yupo},
	editor = {Chan, Yupo and Talburt, John and Talley, Terry M.},
	urldate = {2022-02-08},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-1-4419-0176-7_1},
	keywords = {Data Integration, Entity Resolution, Global Ranking, Incoming Data, Model Repository},
}

@incollection{deaton_semantic_2010,
	location = {Boston, {MA}},
	title = {Semantic Data Matching: Principles and Performance},
	isbn = {978-1-4419-0176-7},
	url = {https://doi.org/10.1007/978-1-4419-0176-7_4},
	series = {International Series in Operations Research \& Management Science},
	shorttitle = {Semantic Data Matching},
	abstract = {Automated and real-time management of customer relationships requires robust and intelligent data matching across widespread and diverse data sources. Simple string matching algorithms, such as dynamic programming, can handle typographical errors in the data, but are less able to match records that require contextual and experiential knowledge. Latent Semantic Indexing ({LSI}) (Berry et al. ; Deerwester et al. is a machine intelligence technique that can match data based upon higher order structure, and is able to handle difficult problems, such as words that have different meanings but the same spelling, are synonymous, or have multiple meanings. Essentially, the technique matches records based upon context, or mathematically quantifying when terms occur in the same record.},
	pages = {77--90},
	booktitle = {Data Engineering: Mining, Information and Intelligence},
	publisher = {Springer {US}},
	author = {Deaton, Russell and Doan, Thao and Schweiger, Tom},
	editor = {Chan, Yupo and Talburt, John and Talley, Terry M.},
	urldate = {2022-02-08},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-1-4419-0176-7_4},
	keywords = {Dispersed Data Sources, Higher Order Structure, Latent Semantic Indexing ({LSI}), Machine Intelligence Techniques, Simple String Matching Algorithm},
}

@incollection{ding_interactive_2010,
	location = {Boston, {MA}},
	title = {Interactive Visualization of Large High-Dimensional Datasets},
	isbn = {978-1-4419-0176-7},
	url = {https://doi.org/10.1007/978-1-4419-0176-7_15},
	series = {International Series in Operations Research \& Management Science},
	abstract = {Nowadays many companies and public organizations use powerful database systems for collecting and managing information. Huge amount of data records are often accumulated within a short period of time. Valuable information is embedded in these data, which could help discover interesting knowledge and significantly assist in decision-making process. However, human beings are not capable of understanding so many data records which often have lots of attributes. The need for automated knowledge extraction is widely recognized, and leads to a rapidly developing market of data analysis and knowledge discovery tools.},
	pages = {335--351},
	booktitle = {Data Engineering: Mining, Information and Intelligence},
	publisher = {Springer {US}},
	author = {Ding, Wei and Chen, Ping},
	editor = {Chan, Yupo and Talburt, John and Talley, Terry M.},
	urldate = {2022-02-08},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-1-4419-0176-7_15},
	keywords = {Data Dimension, Interactive Visualization, Transformation Function, Visual Object, Visualization System},
}

@incollection{duan_delay_2010,
	location = {Boston, {MA}},
	title = {Delay Characteristics of Packet Switched Networks},
	isbn = {978-1-4419-0176-7},
	url = {https://doi.org/10.1007/978-1-4419-0176-7_10},
	series = {International Series in Operations Research \& Management Science},
	abstract = {The rapid growth of the Internet, along with the availability of powerful computers and high-speed networks as low-cost commodity components, is changing the way people do computing and manage information. These new technologies have enabled the utilization of a wide variety of geographically distributed computational resources, including computers, storage systems, data sources, and special devices, as a unified resource. This new paradigm is popularly termed “grid” computing. The federation of highly distributed heterogeneous resources to deliver high-performance computational services is a key feature of grid computing. Computer networks form the basis for resource sharing across geographically distributed sites and many grid applications require the underlying networks guarantee certain levels of delay performance.},
	pages = {203--223},
	booktitle = {Data Engineering: Mining, Information and Intelligence},
	publisher = {Springer {US}},
	author = {Duan, Qiang},
	editor = {Chan, Yupo and Talburt, John and Talley, Terry M.},
	urldate = {2022-02-08},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-1-4419-0176-7_10},
	keywords = {Delay Performance, Leaky Bucket, Output Module, Packet Switch, Switching Fabric},
}

@incollection{ross_parallel_2010,
	location = {Boston, {MA}},
	title = {Parallel File Systems},
	isbn = {978-1-4419-0176-7},
	url = {https://doi.org/10.1007/978-1-4419-0176-7_8},
	series = {International Series in Operations Research \& Management Science},
	abstract = {The success of a {CDI} Grid is dependent upon the design of its storage infrastructure. As seen in Chapter 7, processing in this environment revolves around the simultaneous movement and transformation of data on many compute elements. Effective storage solutions combine hardware and software to meet these needs. The storage hardware selected must provide enough raw throughput for the expected workloads. Typical storage hardware architectures also often provide some redundancy to help in creating a fault tolerant system. Storage software, specifically file systems, must organize this storage hardware into a single logical space, provide efficient mechanisms for accessing that space, and hide common hardware failures from compute elements.},
	pages = {143--168},
	booktitle = {Data Engineering: Mining, Information and Intelligence},
	publisher = {Springer {US}},
	author = {Ross, Robert and Carns, Philip and Metheny, David},
	editor = {Chan, Yupo and Talburt, John and Talley, Terry M.},
	urldate = {2022-02-08},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-1-4419-0176-7_8},
	keywords = {Access Pattern, File Region, File System, Internet Engineer Task Force, Message Passing Interface},
}

@incollection{gibbs_declarative_2010,
	location = {Boston, {MA}},
	title = {A Declarative Approach to Entity Resolution},
	isbn = {978-1-4419-0176-7},
	url = {https://doi.org/10.1007/978-1-4419-0176-7_2},
	series = {International Series in Operations Research \& Management Science},
	abstract = {As companies gather and process more data from disparate sources, they are relying more heavily on entity resolution. Currently, creating an entity resolution system is a very procedural process. Blocking, transitive closure, and matching must all be pieced together whether by an Extract, Transform, and Load ({ETL}) tool or by a custom program (Galhardas et al. 2000). This is similar to the state of data querying before the advent of the Structured Query Language ({SQL}). In this chapter, a declarative approach to entity resolution is presented that gives the user the ability to specify what he or she would like resolved while allowing a code generator to determine the best way to resolve it. This chapter does not explore algorithms for blocking, transitive closure, clustering, or matching, but instead refers to papers on those subjects written by other authors (Baxter et al. 2003; Gu and Baxter 2004; Winkler 2000, 2003; Jaro 1989; Bhattacharya and Getoor 2006). Instead a background and defense of entity resolution and declarative languages is presented with a declarative solution and a possible representation.},
	pages = {17--38},
	booktitle = {Data Engineering: Mining, Information and Intelligence},
	publisher = {Springer {US}},
	author = {Gibbs, Tanton H.},
	editor = {Chan, Yupo and Talburt, John and Talley, Terry M.},
	urldate = {2022-02-08},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-1-4419-0176-7_2},
	keywords = {Closure Attribute, Input Reference, Match Function, Record Linkage, Transitive Closure},
}

@incollection{talley_grid_2010,
	location = {Boston, {MA}},
	title = {A Grid Operating Environment for {CDI}},
	isbn = {978-1-4419-0176-7},
	url = {https://doi.org/10.1007/978-1-4419-0176-7_7},
	series = {International Series in Operations Research \& Management Science},
	abstract = {The purpose of this chapter is to discuss how a grid operating environment is well suited to the tasks associated with Customer Data Integration ({CDI} ) and describe a logical organization of a grid that is targeted at addressing this application. More specifically, recall from the introductory},
	pages = {119--142},
	booktitle = {Data Engineering: Mining, Information and Intelligence},
	publisher = {Springer {US}},
	author = {Talley, Terry M.},
	editor = {Chan, Yupo and Talburt, John and Talley, Terry M.},
	urldate = {2022-02-08},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-1-4419-0176-7_7},
	keywords = {Data Grid, File System, Service Grid, Service Instance, Virtual Machine},
}

@incollection{mete_knowledge_2010,
	location = {Boston, {MA}},
	title = {Knowledge Discovery in Textual Databases: A Concept-Association Mining Approach},
	isbn = {978-1-4419-0176-7},
	url = {https://doi.org/10.1007/978-1-4419-0176-7_11},
	series = {International Series in Operations Research \& Management Science},
	shorttitle = {Knowledge Discovery in Textual Databases},
	abstract = {The number of scientific publications is exploding as online digital libraries and the World Wide Web grow. {MEDLINE}, the premier bibliographic database of the National Library of Medicine ({NLM}) , contains about 18 million records from more than 7,300 different publications dating from 1965; it is growing by about 400,000 citations each year. The explosive growth of information in textual documents creates great need for techniques for knowledge discovery from text collections.},
	pages = {225--243},
	booktitle = {Data Engineering: Mining, Information and Intelligence},
	publisher = {Springer {US}},
	author = {Mete, Mutlu and Yuruk, Nurcan and Xu, Xiaowei and Berleant, Daniel},
	editor = {Chan, Yupo and Talburt, John and Talley, Terry M.},
	urldate = {2022-02-08},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-1-4419-0176-7_11},
	keywords = {Association Rule, Association Rule Mining, Rule Mining, Spread Cortical Depression, Support Threshold},
}

@incollection{hoffman_performance_2010,
	location = {Boston, {MA}},
	title = {Performance Modeling of Enterprise Grids},
	isbn = {978-1-4419-0176-7},
	url = {https://doi.org/10.1007/978-1-4419-0176-7_9},
	series = {International Series in Operations Research \& Management Science},
	abstract = {Modeling has long been recognized as an invaluable tool for predicting the performance behavior of computer systems. Modeling software, both commercial and open source, is widely used as a guide for the development of new systems and the upgrading of exiting ones. Tools such as queuing network models, stochastic Petri nets, and event driven simulation are in common use for stand-alone computer systems and networks. Unfortunately, no set of comprehensive tools exists for modeling complex distributed computing environments such as the ones found in emerging grid deployments. With the rapid advance of grid computing, the need for improved modeling tools specific to the grid environment has become evident. This chapter addresses concepts, methodologies, and tools that are useful when designing, implementing, and tuning the performance in grid and cluster environments},
	pages = {169--201},
	booktitle = {Data Engineering: Mining, Information and Intelligence},
	publisher = {Springer {US}},
	author = {Hoffman, Doug L. and Apon, Amy and Dowdy, Larry and Lu, Baochuan and Hamm, Nathan and Ngo, Linh and Bui, Hung},
	editor = {Chan, Yupo and Talburt, John and Talley, Terry M.},
	urldate = {2022-02-08},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-1-4419-0176-7_9},
	keywords = {Capacity Planning, First Come First Serve, Queueing Network Model, Service Level Agreement, Shared Service},
}

@incollection{kockara_immersive_2010,
	location = {Boston, {MA}},
	title = {Immersive Visualization of Cellular Structures},
	isbn = {978-1-4419-0176-7},
	url = {https://doi.org/10.1007/978-1-4419-0176-7_17},
	series = {International Series in Operations Research \& Management Science},
	abstract = {Bioimaging is an immensely powerful tool in biomedical research that aids the understanding of cellular structures and the molecular events in the cell. Understanding the biological functions within the cell requires an in-depth understanding of all the diverse functions of the microscopic structures and the molecular interactions between macromolecules in their natural environment. Traditionally, cell biologists have used light microscopy techniques to study topographical characterization of cell surfaces. The optical properties of a light microscope give occasion to a blurring phenomenon similar to the one with a conventional microscope with the result that images are characterized by low resolution and magnification. We address the challenging task of enhancing the image produced by a light microscope by reconstructing a stack of monoscopic images from a light microscope to produce a single image with inferential and useful information than that obtained at the best focus level. We believe such an approach will enable a wider base of microscope users to take advantage of light microscope imaging in biological research.},
	pages = {389--402},
	booktitle = {Data Engineering: Mining, Information and Intelligence},
	publisher = {Springer {US}},
	author = {Kockara, Sinan and Ali, Nawab and Dagtas, Serhan},
	editor = {Chan, Yupo and Talburt, John and Talley, Terry M.},
	urldate = {2022-02-08},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-1-4419-0176-7_17},
	keywords = {Focus Level, Immersive Virtual Reality, Layer Image, Texture Mapping, Virtual Reality},
}

@incollection{zhu_information_2010,
	location = {Boston, {MA}},
	title = {Information Quality Framework for Verifiable Intelligence Products},
	isbn = {978-1-4419-0176-7},
	url = {https://doi.org/10.1007/978-1-4419-0176-7_14},
	series = {International Series in Operations Research \& Management Science},
	abstract = {Organizations have been increasingly investing in technology to collect and process vast volumes of data. Even so, they often find themselves stymied in their efforts to effectively use the data to improve business processes and to make better decisions. This difficulty is often caused by information quality issues within the organization and other related organizations.},
	pages = {315--333},
	booktitle = {Data Engineering: Mining, Information and Intelligence},
	publisher = {Springer {US}},
	author = {Zhu, Hongwei and Wang, Richard Y.},
	editor = {Chan, Yupo and Talburt, John and Talley, Terry M.},
	urldate = {2022-02-08},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-1-4419-0176-7_14},
	keywords = {Central Intelligence Agency, Enterprise Architecture, Information Quality, Intelligence Collection, Intelligence Community},
	file = {Eingereichte Version:C\:\\Users\\micha\\Zotero\\storage\\H6Q7Y335\\Zhu und Wang - 2010 - Information Quality Framework for Verifiable Intel.pdf:application/pdf},
}

@incollection{li_transitive_2010,
	location = {Boston, {MA}},
	title = {Transitive Closure of Data Records: Application and Computation},
	isbn = {978-1-4419-0176-7},
	url = {https://doi.org/10.1007/978-1-4419-0176-7_3},
	series = {International Series in Operations Research \& Management Science},
	shorttitle = {Transitive Closure of Data Records},
	abstract = {This chapter considers a record- grouping problem, which is called the transitive closure problem. The problem arises from the area of efficient information processing aiming at improving data quality and information quality. To provide a context in which the problem could be better understood, we consider the importance of data quality and information quality and discuss samples of related work in this introduction.},
	pages = {39--75},
	booktitle = {Data Engineering: Mining, Information and Intelligence},
	publisher = {Springer {US}},
	author = {Li, Wing Ning and Bheemavaram, Roopa and Zhang, Xiaojun},
	editor = {Chan, Yupo and Talburt, John and Talley, Terry M.},
	urldate = {2022-02-08},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-1-4419-0176-7_3},
	keywords = {Input File, Local Cluster, Local Pair, Sequential Algorithm, Transitive Closure},
}

@incollection{chan_visualization_2010,
	location = {Boston, {MA}},
	title = {Visualization and Ontology of Geospatial Intelligence},
	isbn = {978-1-4419-0176-7},
	url = {https://doi.org/10.1007/978-1-4419-0176-7_18},
	series = {International Series in Operations Research \& Management Science},
	abstract = {Recent events have deepened our conviction that many human endeavors are best described in a geospatial context. This is evidenced in the prevalence of location-based services, as afforded by the ubiquitous cell phone usage. It is also manifested by the popularity of such internet engines as Google Earth. As we commute to work, travel on business or pleasure, we make decisions based on the geospatial information provided by such location-based services. When corporations devise their business plans, they also rely heavily on such geospatial data. By definition, local, state and federal governments provide services according to geographic boundaries. One estimate suggests that 85 percent of data contain spatial attributes.},
	pages = {403--429},
	booktitle = {Data Engineering: Mining, Information and Intelligence},
	publisher = {Springer {US}},
	author = {Chan, Yupo},
	editor = {Chan, Yupo and Talburt, John and Talley, Terry M.},
	urldate = {2022-02-08},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-1-4419-0176-7_18},
	keywords = {Bayesian Belief Network, Geographic Information System, Geospatial Data, Spatial Object, Spatial Weight},
}

@incollection{cunningham_designing_2010,
	location = {Boston, {MA}},
	title = {Designing a Flexible Framework for a Table Abstraction},
	isbn = {978-1-4419-0176-7},
	url = {https://doi.org/10.1007/978-1-4419-0176-7_13},
	series = {International Series in Operations Research \& Management Science},
	abstract = {In a provocative essay from the mid-1980s, Brooks asserts that “building software will always be hard” because software systems are inherently complex, must conform to all sorts of physical, human, and software interfaces, must change as the system requirements evolve, and are inherently invisible entities (Brooks 1986). A decade later Brooks again observes, “The best way to attack the essence of building software is not to build it at all” (Brooks 1995). That is, software engineers should reuse both software and, more importantly, software designs.},
	pages = {279--314},
	booktitle = {Data Engineering: Mining, Information and Intelligence},
	publisher = {Springer {US}},
	author = {Cunningham, H. Conrad and Liu, Yi and Wang, Jingyi},
	editor = {Chan, Yupo and Talburt, John and Talley, Terry M.},
	urldate = {2022-02-08},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-1-4419-0176-7_13},
	keywords = {Abstract Data Type, Design Contract, Design Pattern, Framework Design, Storage Layer},
}

@incollection{kountchev_image_2010,
	location = {Boston, {MA}},
	title = {Image Watermarking Based on Pyramid Decomposition with {CH} Transform},
	isbn = {978-1-4419-0176-7},
	url = {https://doi.org/10.1007/978-1-4419-0176-7_16},
	series = {International Series in Operations Research \& Management Science},
	abstract = {The new method for digital image watermarking , presented in this chapter, could be used for intellectual property right protection of digital still images of any kind (natural, scanned documents, computer graphics, etc.). The method is suitable for distance learning applications; access control for medical or biometric information in corresponding databases; detection of forgeries and illegal distribution of electronic or scanned documents; data hiding in medical, cartographic, and other images; authorized contents editing; etc.},
	pages = {353--387},
	booktitle = {Data Engineering: Mining, Information and Intelligence},
	publisher = {Springer {US}},
	author = {Kountchev, R. and Milanova, M. and Todorov, Vl. and Kountcheva, R.},
	editor = {Chan, Yupo and Talburt, John and Talley, Terry M.},
	urldate = {2022-02-08},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-1-4419-0176-7_16},
	keywords = {Difference Matrix, Hide Data, {JPEG} Compression, Watermark Extraction, Watermark Image},
}

@incollection{bahrami_mining_2010,
	location = {Boston, {MA}},
	title = {Mining E-Documents to Uncover Structures},
	isbn = {978-1-4419-0176-7},
	url = {https://doi.org/10.1007/978-1-4419-0176-7_12},
	series = {International Series in Operations Research \& Management Science},
	abstract = {An e-Document, D, coded in {HTML} is comprised of a body and a head. The body includes the contents of the e-document, and the head includes, among other things, metadata.},
	pages = {245--278},
	booktitle = {Data Engineering: Mining, Information and Intelligence},
	publisher = {Springer {US}},
	author = {Bahrami, Azita},
	editor = {Chan, Yupo and Talburt, John and Talley, Terry M.},
	urldate = {2022-02-08},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-1-4419-0176-7_12},
	keywords = {Explicit Term, Logical Structure, Multivalue Dependency, Order Number, Precedence Number},
}

@collection{chan_data_2010,
	location = {Boston, {MA}},
	title = {Data Engineering: Mining, Information and Intelligence},
	volume = {132},
	isbn = {978-1-4419-0175-0 978-1-4419-0176-7},
	url = {http://link.springer.com/10.1007/978-1-4419-0176-7},
	series = {International Series in Operations Research \& Management Science},
	shorttitle = {Data Engineering},
	publisher = {Springer {US}},
	editor = {Chan, Yupo and Talburt, John and Talley, Terry M.},
	urldate = {2022-02-08},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-1-4419-0176-7},
	file = {Chan et al. - 2010 - Data Engineering Mining, Information and Intellig.pdf:C\:\\Users\\micha\\Zotero\\storage\\4HUBZ4B4\\Chan et al. - 2010 - Data Engineering Mining, Information and Intellig.pdf:application/pdf},
}

@collection{chan_data_2010-1,
	location = {Boston, {MA}},
	title = {Data Engineering: Mining, Information and Intelligence},
	volume = {132},
	isbn = {978-1-4419-0175-0 978-1-4419-0176-7},
	url = {http://link.springer.com/10.1007/978-1-4419-0176-7},
	series = {International Series in Operations Research \& Management Science},
	shorttitle = {Data Engineering},
	publisher = {Springer {US}},
	editor = {Chan, Yupo and Talburt, John and Talley, Terry M.},
	urldate = {2022-02-08},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-1-4419-0176-7},
	file = {Chan et al. - 2010 - Data Engineering Mining, Information and Intellig.pdf:C\:\\Users\\micha\\Zotero\\storage\\V4ECVFMS\\Chan et al. - 2010 - Data Engineering Mining, Information and Intellig.pdf:application/pdf},
}

@collection{chan_data_2010-2,
	location = {Boston, {MA}},
	title = {Data Engineering: Mining, Information and Intelligence},
	volume = {132},
	isbn = {978-1-4419-0175-0 978-1-4419-0176-7},
	url = {http://link.springer.com/10.1007/978-1-4419-0176-7},
	series = {International Series in Operations Research \& Management Science},
	shorttitle = {Data Engineering},
	publisher = {Springer {US}},
	editor = {Chan, Yupo and Talburt, John and Talley, Terry M.},
	urldate = {2022-02-08},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-1-4419-0176-7},
	file = {Chan et al. - 2010 - Data Engineering Mining, Information and Intellig.pdf:C\:\\Users\\micha\\Zotero\\storage\\CDFY9SZE\\Chan et al. - 2010 - Data Engineering Mining, Information and Intellig.pdf:application/pdf},
}

@article{jordon_measuring_2018,
	title = {Measuring the quality of Synthetic data for use in competitions},
	url = {http://arxiv.org/abs/1806.11345},
	abstract = {Machine learning has the potential to assist many communities in using the large datasets that are becoming more and more available. Unfortunately, much of that potential is not being realized because it would require sharing data in a way that compromises privacy. In order to overcome this hurdle, several methods have been proposed that generate synthetic data while preserving the privacy of the real data. In this paper we consider a key characteristic that synthetic data should have in order to be useful for machine learning researchers - the relative performance of two algorithms (trained and tested) on the synthetic dataset should be the same as their relative performance (when trained and tested) on the original dataset.},
	journaltitle = {{arXiv}:1806.11345 [cs, stat]},
	author = {Jordon, James and Yoon, Jinsung and van der Schaar, Mihaela},
	urldate = {2022-02-09},
	date = {2018-06-29},
	eprinttype = {arxiv},
	eprint = {1806.11345},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\micha\\Zotero\\storage\\JWWD25XT\\Jordon et al. - 2018 - Measuring the quality of Synthetic data for use in.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\micha\\Zotero\\storage\\663WJZFV\\1806.html:text/html},
}

@article{shorten_survey_2019,
	title = {A survey on Image Data Augmentation for Deep Learning},
	volume = {6},
	issn = {2196-1115},
	url = {https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0},
	doi = {10.1186/s40537-019-0197-0},
	abstract = {Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on {GANs} are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.},
	pages = {60},
	number = {1},
	journaltitle = {Journal of Big Data},
	shortjournal = {J Big Data},
	author = {Shorten, Connor and Khoshgoftaar, Taghi M.},
	urldate = {2022-02-09},
	date = {2019-12},
	langid = {english},
	file = {Shorten und Khoshgoftaar - 2019 - A survey on Image Data Augmentation for Deep Learn.pdf:C\:\\Users\\micha\\Zotero\\storage\\QRQ2LMRG\\Shorten und Khoshgoftaar - 2019 - A survey on Image Data Augmentation for Deep Learn.pdf:application/pdf},
}

@inproceedings{luo_eeg_2018,
	title = {{EEG} Data Augmentation for Emotion Recognition Using a Conditional Wasserstein {GAN}},
	doi = {10.1109/EMBC.2018.8512865},
	abstract = {Due to the lack of electroencephalography ({EEG}) data, it is hard to build an emotion recognition model with high accuracy from {EEG} signals using machine learning approach. Inspired by generative adversarial networks ({GANs}), we introduce a Conditional Wasserstein {GAN} ({CWGAN}) framework for {EEG} data augmentation to enhance {EEG}-based emotion recognition. A Wasserstein {GAN} with gradient penalty is adopted to generate realistic-like {EEG} data in differential entropy ({DE}) form. Three indicators are used to judge the qualities of the generated high-dimensional {EEG} data, and only high quality data are appended to supplement the data manifold, which leads to better classification of different emotions. We evaluate the proposed {CWGAN} framework on two public {EEG} datasets for emotion recognition, namely {SEED} and {DEAP}. The experimental results demonstrate that using the {EEG} data generated by {CWGAN} significantly improves the accuracies of emotion recognition models.},
	eventtitle = {2018 40th Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society ({EMBC})},
	pages = {2535--2538},
	booktitle = {2018 40th Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society ({EMBC})},
	author = {Luo, Yun and Lu, Bao-Liang},
	date = {2018-07},
	note = {{ISSN}: 1558-4615},
	keywords = {Brain modeling, Electroencephalography, Emotion recognition, Gallium nitride, Generative adversarial networks, Generators, Training},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\micha\\Zotero\\storage\\NZ5GBGZG\\Luo und Lu - 2018 - EEG Data Augmentation for Emotion Recognition Usin.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\micha\\Zotero\\storage\\7E6TJPBC\\8512865.html:text/html},
}

@online{noauthor_background_nodate,
	title = {Background: What is a Generative Model? {\textbar} Generative Adversarial Networks},
	url = {https://developers.google.com/machine-learning/gan/generative},
	shorttitle = {Background},
	titleaddon = {Google Developers},
	urldate = {2022-02-09},
	langid = {english},
	file = {Snapshot:C\:\\Users\\micha\\Zotero\\storage\\UW7V4YMW\\generative.html:text/html},
}

@article{creswell_generative_2018,
	title = {Generative Adversarial Networks: An Overview},
	volume = {35},
	issn = {1053-5888},
	url = {http://arxiv.org/abs/1710.07035},
	doi = {10.1109/MSP.2017.2765202},
	shorttitle = {Generative Adversarial Networks},
	abstract = {Generative adversarial networks ({GANs}) provide a way to learn deep representations without extensively annotated training data. They achieve this through deriving backpropagation signals through a competitive process involving a pair of networks. The representations that can be learned by {GANs} may be used in a variety of applications, including image synthesis, semantic image editing, style transfer, image super-resolution and classification. The aim of this review paper is to provide an overview of {GANs} for the signal processing community, drawing on familiar analogies and concepts where possible. In addition to identifying different methods for training and constructing {GANs}, we also point to remaining challenges in their theory and application.},
	pages = {53--65},
	number = {1},
	journaltitle = {{IEEE} Signal Processing Magazine},
	shortjournal = {{IEEE} Signal Process. Mag.},
	author = {Creswell, Antonia and White, Tom and Dumoulin, Vincent and Arulkumaran, Kai and Sengupta, Biswa and Bharath, Anil A.},
	urldate = {2022-02-09},
	date = {2018-01},
	eprinttype = {arxiv},
	eprint = {1710.07035},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\micha\\Zotero\\storage\\GUBD4MP3\\Creswell et al. - 2018 - Generative Adversarial Networks An Overview.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\micha\\Zotero\\storage\\22IBTP9L\\1710.html:text/html},
}